<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width" />
	<title>Decibel visualization</title>
	<style>
		html,
		body {
			height: 100%;
			margin: 0;
			background-color: white;
		}

		.container {
			position: relative;
			width: 100%;
			height: 100%;
		}

		#controls {
			z-index: 100;
			display: flex;
			flex-direction: column;
			width: 75px;
			margin: auto;
			left: 50%;
			top: 50%;
			transform: translate(-50%, -50%);
			position: absolute;
			cursor: pointer;
			font-family: sans-serif;
		}

		#controls label {
			margin: auto;
			font-size: 12px;
			color: white;
		}

		#controls input {
			width: 75px;
			background-color: #27272a;
			color: white;
			margin: auto;
			cursor: pointer;
			border: none;
			font-family: sans-serif;

		}

		#controls input[type='button'] {
			background: black;
		}

		.control {
			margin: 4px auto;
			text-align: center;
		}

		.gain::-webkit-slider-thumb {
			-webkit-appearance: none;
			width: 16px;
			height: 16px;
			border-radius: 10px;
			background-color: white;
			overflow: visible;
			cursor: pointer;
		}

		.gain {
			-webkit-appearance: none;
			background-color: rgb(200, 200, 200);
		}



		#visualizer {
			margin: auto;
			left: 50%;
			top: 50%;
			transform: translate(-50%, -50%);
			position: absolute;
			z-index: 10;
		}

		#background {
			margin: auto;
			left: 50%;
			top: 50%;
			transform: translate(-50%, -50%);
			position: absolute;
			z-index: 1;
		}
	</style>
</head>

<body>
	<div class="container">
		<audio></audio>
		<canvas id="visualizer" width="800" height="800"></canvas>
		<canvas id="background" width="800" height="800"></canvas>
		<div id="controls">
			<input type="button" data-playing="false" role="switch" aria-checked="false" id="button" value="Play" />
		</div>
	</div>
	<script>
		const audioElement = document.querySelector("audio");
		let audioContext;
		let track;
		let analyser;
		let javascriptNode;
		let bufferLength;
		let arrayBuffer;
		const playButton = document.querySelector("#button");
		const canvasElt = document.querySelector("#visualizer");
		const canvasContext = canvasElt.getContext("2d");
		const backgroundElt = document.querySelector("#background");
		const backgroundContext = backgroundElt.getContext("2d");;
		const bottomLeft = { x: 0, y: canvasElt.height }

		playButton.addEventListener(
			"click",
			() => {
				if (!audioContext) {
					init();
				}
				if (audioContext.state === "suspended") {
					audioContext.resume().then(() => {
						audioElement.play();
						visualize();
						playButton.dataset.playing = "true";
						playButton.value = 'Pause';
					});
				}
				if (playButton.dataset.playing === "false") {
					audioElement.play();
					visualize();
					playButton.dataset.playing = "true";
					playButton.value = 'Pause';
				} else if (playButton.dataset.playing === "true") {
					audioContext.suspend().then(() => {
						audioElement.pause();
						playButton.dataset.playing = "false";
						playButton.value = 'Play';
					})
				}
				let state =
					playButton.getAttribute("aria-checked") === "true" ? true : false;
				playButton.setAttribute("aria-checked", state ? "false" : "true");
			},
			false
		);
		audioElement.addEventListener(
			"ended",
			() => {
				playButton.dataset.playing = "false";
				playButton.setAttribute("aria-checked", "false");
			},
			false
		);
		function init() {
			setSong();
			audioContext = new AudioContext();
			track = new MediaElementAudioSourceNode(audioContext, {
				mediaElement: audioElement,
			});
			javascriptNode = audioContext.createScriptProcessor(
				1024,
				1,
				1

			);
			track.connect(audioContext.destination);
			analyser = audioContext.createAnalyser();
			analyser.fftSize = 2048;
			bufferLength = analyser.frequencyBinCount;
			dataArray = new Uint8Array(bufferLength);
			track.connect(analyser);
			analyser.connect(audioContext.destination);
			javascriptNode.connect(audioContext.destination);
		}

		function visualize() {
			if (audioContext.state === "running") {
				javascriptNode.onaudioprocess = () => {
					requestAnimationFrame(() => {
						const data = getDecibelData();
						canvasContext.clearRect(
							0,
							0,
							canvasElt.width,
							canvasElt.height
						);
						drawByte(data);
						fillBackground();
					});
				}
			}
		}

		function getDecibelData() {
			const frequencyData = getFrequencyData();
			const decibelData = Array.from(frequencyData).map(convertDb);
			let sum = 0;
			for (let i = 0; i < decibelData.length; i++) {
				sum += decibelData[i];
			}
			return sum / decibelData.length;
		}

		function getFrequencyData() {
			analyser.getByteFrequencyData(dataArray);
			return dataArray;
		}

		function convertDb(value) {
			const floor = 1e-10;
			return 20 * Math.log10(value + floor / 255);
		}

		function drawByte(decibels) {
			canvasContext.fillStyle = 'white';
			const numPoints = 28;
			const step = 13;
			const angle = (2 * Math.PI) / numPoints;
			canvasContext.beginPath();
			const decibelVariable = 600 + decibels;
			for (let i = 0; i <= numPoints; i++) {
				const x = bottomLeft.x + decibelVariable * Math.cos(i * step * angle);
				const y = bottomLeft.y + (600 + decibels) * Math.sin(i * step * angle);
				if (i === 0) {
					canvasContext.moveTo(x, y);
				} else {
					canvasContext.lineTo(x, y);
				}
			}
			canvasContext.closePath();
			canvasContext.fill();
		}

		function fillBackground() {
			const now = audioContext.currentTime;
			const gradient = backgroundContext.createLinearGradient(0, 0, canvasElt.width * Math.cos(now), canvasElt.height * Math.sin(now));
			gradient.addColorStop(0, getVariableOne());
			gradient.addColorStop(.50, getVariableTwo());
			backgroundContext.fillStyle = gradient;
			backgroundContext.fillRect(0, 0, canvasElt.width, canvasElt.height);
		}

		// Code lab! Try adjusting the variables and functions. 

		function setSong() {
			audioElement.src = '/audio/propagation.mp3';
		}

		function getVariableOne() {
			const now = audioContext.currentTime;
			const duration = audioElement.duration;

			/*
			This variable creates a background color for the AADL byte based on the duration 
			of the song. Values in rgb format (red, green, blue) have a max value of 255 and a
			minimum value of 0. It's useful to use known values like these as a way to prevent
			broken values from sneaking in. In this example, we're dividing the current timestamp
			by the full song duration to represent a percentage of the maximum value (255). That
			way, the result will always fall between the minium and maximum.

			By default, the red value is slowly reducing from the maximum value (255) by subtracting 
			the current runtime expressed as a percentage of the maximum value. The green value is set
			to zero. And the blue value will slowly increase from the minimum value based on the run time.

			Try adjusting the red, green, and blue variables to change the background color!

			Try changing the red value to "255 - (255 * (now * 5/ duration)))" â€” the colors will change faster,
			because the "now" variable is being multiplied. This will result overflow values, but that's okay!

			In the blue variable, try referencing red or green to make a new value. 
			For example: 255 * (red / 255);
			This creates a percentage of 255 based on the red and green values
			*/

			const red = 255 - (255 * (now / duration));
			const green = red * .75;
			const blue = 0;

			return 'rgb(' + red + ', ' + green + ',' + blue + ')';
		}
		function getVariableTwo() {
			const now = audioContext.currentTime;
			const duration = audioElement.duration;

			/*
			This variable creates a gradient color to contrast the color above. By default, 
			0,0,0 returns black. Try changing each of these to numbers between 0 and 255.
			*/

			const red = 0;
			const green = 0;
			const blue = 0;

			return 'rgb(' + red + ', ' + green + ',' + blue + ')';
		}
	</script>
</body>

</html>